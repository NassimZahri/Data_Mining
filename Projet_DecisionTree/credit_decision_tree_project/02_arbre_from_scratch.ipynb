{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 - Implementation d'un Arbre de Decision \"From Scratch\"\n",
    "\n",
    "Ce notebook presente l'implementation complete d'un arbre de decision binaire sans utiliser de bibliotheques specialisees.\n",
    "\n",
    "**Contenu:**\n",
    "- Chargement des donnees depuis GitHub\n",
    "- Structure de donnees pour l'arbre\n",
    "- Algorithme de recherche du meilleur split\n",
    "- Construction recursive de l'arbre\n",
    "- Fonction de prediction\n",
    "\n",
    "**Auteur**: Projet Data Mining - Arbres de Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des bibliotheques et chargement des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Chargement des donnees depuis GitHub\n",
    "base_url = 'https://raw.githubusercontent.com/NassimZahri/Data_Mining/main/data/'\n",
    "df = pd.read_csv(base_url + 'credit_simple.csv')\n",
    "\n",
    "print(\"Dimensions du dataset:\", df.shape)\n",
    "print(\"\\nApercu des donnees:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration des donnees\n",
    "print(\"Types des colonnes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nValeurs uniques par colonne:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation des donnees\n",
    "# Separation des features et de la cible\n",
    "X = df.drop('defaut', axis=1)\n",
    "y = df['defaut']\n",
    "\n",
    "# Encodage one-hot des variables categorielles\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Encodage de la variable cible\n",
    "y_encoded = y.map({'oui': 1, 'non': 0})\n",
    "\n",
    "print(\"Features apres encodage:\")\n",
    "print(X_encoded.columns.tolist())\n",
    "print(\"\\nDimensions:\", X_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Structure de donnees: Classe Node\n",
    "\n",
    "Chaque noeud de l'arbre contient:\n",
    "- Pour un noeud interne: l'attribut de split, le seuil, et les sous-arbres gauche/droit\n",
    "- Pour une feuille: la valeur de prediction (classe majoritaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Classe representant un noeud dans l'arbre de decision.\n",
    "    \n",
    "    Attributs:\n",
    "    ----------\n",
    "    feature : str ou None\n",
    "        Nom de l'attribut utilise pour le split (None si feuille)\n",
    "    threshold : float ou None\n",
    "        Valeur seuil pour le split (None si feuille)\n",
    "    left : Node ou None\n",
    "        Sous-arbre gauche (instances <= threshold)\n",
    "    right : Node ou None\n",
    "        Sous-arbre droit (instances > threshold)\n",
    "    value : int ou None\n",
    "        Classe predite (seulement pour les feuilles)\n",
    "    samples : int\n",
    "        Nombre d'exemples dans ce noeud\n",
    "    impurity : float\n",
    "        Impurete du noeud\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, \n",
    "                 value=None, samples=0, impurity=0.0):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.samples = samples\n",
    "        self.impurity = impurity\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        \"\"\"Retourne True si le noeud est une feuille.\"\"\"\n",
    "        return self.value is not None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.is_leaf():\n",
    "            return f\"Leaf(value={self.value}, samples={self.samples})\"\n",
    "        return f\"Node(feature={self.feature}, threshold={self.threshold}, samples={self.samples})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonction de calcul de l'impurete (Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Calcule l'indice de Gini pour un vecteur de labels.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    y : array-like\n",
    "        Vecteur de labels de classe\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    float\n",
    "        Indice de Gini\n",
    "    \"\"\"\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    \n",
    "    counts = Counter(y)\n",
    "    total = len(y)\n",
    "    probs = [count / total for count in counts.values()]\n",
    "    return 1 - sum(p**2 for p in probs)\n",
    "\n",
    "\n",
    "# Test de la fonction\n",
    "print(\"Test de la fonction gini():\")\n",
    "print(f\"  Gini([1,1,1,1,0,0,0,0]) = {gini([1,1,1,1,0,0,0,0]):.4f} (attendu: 0.5)\")\n",
    "print(f\"  Gini([1,1,1,1,1,1,1,1]) = {gini([1,1,1,1,1,1,1,1]):.4f} (attendu: 0.0)\")\n",
    "print(f\"  Gini([1,1,1,1,1,1,0,0]) = {gini([1,1,1,1,1,1,0,0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algorithme de recherche du meilleur split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y):\n",
    "    \"\"\"\n",
    "    Trouve le meilleur split pour un noeud donne.\n",
    "    \n",
    "    Pour chaque attribut, teste tous les seuils possibles et\n",
    "    retourne celui qui maximise le gain d'information.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Matrice des features\n",
    "    y : Series\n",
    "        Vecteur des labels\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    tuple (str, float, float)\n",
    "        (nom_feature, seuil, gain)\n",
    "    \"\"\"\n",
    "    best_gain = 0\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    \n",
    "    # Impurete du noeud parent\n",
    "    parent_impurity = gini(y)\n",
    "    n_samples = len(y)\n",
    "    \n",
    "    # Parcourir tous les attributs\n",
    "    for feature in X.columns:\n",
    "        # Obtenir les valeurs uniques triees pour les seuils candidats\n",
    "        thresholds = sorted(X[feature].unique())\n",
    "        \n",
    "        # Tester chaque seuil\n",
    "        for threshold in thresholds:\n",
    "            # Diviser les donnees\n",
    "            left_mask = X[feature] <= threshold\n",
    "            right_mask = X[feature] > threshold\n",
    "            \n",
    "            left_y = y[left_mask]\n",
    "            right_y = y[right_mask]\n",
    "            \n",
    "            # Ignorer les splits qui ne divisent pas les donnees\n",
    "            if len(left_y) == 0 or len(right_y) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculer l'impurete ponderee des enfants\n",
    "            w_left = len(left_y) / n_samples\n",
    "            w_right = len(right_y) / n_samples\n",
    "            \n",
    "            child_impurity = w_left * gini(left_y) + w_right * gini(right_y)\n",
    "            \n",
    "            # Calculer le gain\n",
    "            gain = parent_impurity - child_impurity\n",
    "            \n",
    "            # Mettre a jour le meilleur split\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "    \n",
    "    return best_feature, best_threshold, best_gain\n",
    "\n",
    "\n",
    "# Test de la fonction\n",
    "print(\"Test de best_split():\")\n",
    "feature, threshold, gain = best_split(X_encoded, y_encoded)\n",
    "print(f\"  Meilleur split: {feature} <= {threshold} (gain={gain:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construction recursive de l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, y, depth=0, max_depth=3, min_samples_leaf=1):\n",
    "    \"\"\"\n",
    "    Construit un arbre de decision de maniere recursive.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Matrice des features\n",
    "    y : Series\n",
    "        Vecteur des labels\n",
    "    depth : int\n",
    "        Profondeur actuelle dans l'arbre\n",
    "    max_depth : int\n",
    "        Profondeur maximale autorisee\n",
    "    min_samples_leaf : int\n",
    "        Nombre minimum d'echantillons dans une feuille\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    Node\n",
    "        Racine de l'arbre (ou sous-arbre)\n",
    "    \"\"\"\n",
    "    n_samples = len(y)\n",
    "    n_classes = len(set(y))\n",
    "    impurity = gini(y)\n",
    "    \n",
    "    # Conditions d'arret:\n",
    "    # 1. Noeud pur (une seule classe)\n",
    "    # 2. Profondeur maximale atteinte\n",
    "    # 3. Pas assez d'echantillons\n",
    "    if n_classes == 1 or depth >= max_depth or n_samples < min_samples_leaf * 2:\n",
    "        # Creer une feuille avec la classe majoritaire\n",
    "        majority_class = y.mode()[0]\n",
    "        return Node(value=majority_class, samples=n_samples, impurity=impurity)\n",
    "    \n",
    "    # Trouver le meilleur split\n",
    "    feature, threshold, gain = best_split(X, y)\n",
    "    \n",
    "    # Si aucun split ameliore l'impurete, creer une feuille\n",
    "    if feature is None or gain <= 0:\n",
    "        majority_class = y.mode()[0]\n",
    "        return Node(value=majority_class, samples=n_samples, impurity=impurity)\n",
    "    \n",
    "    # Diviser les donnees\n",
    "    left_mask = X[feature] <= threshold\n",
    "    right_mask = X[feature] > threshold\n",
    "    \n",
    "    # Construire recursivement les sous-arbres\n",
    "    left_subtree = build_tree(\n",
    "        X[left_mask], y[left_mask], \n",
    "        depth + 1, max_depth, min_samples_leaf\n",
    "    )\n",
    "    right_subtree = build_tree(\n",
    "        X[right_mask], y[right_mask], \n",
    "        depth + 1, max_depth, min_samples_leaf\n",
    "    )\n",
    "    \n",
    "    # Creer le noeud interne\n",
    "    return Node(\n",
    "        feature=feature, \n",
    "        threshold=threshold,\n",
    "        left=left_subtree, \n",
    "        right=right_subtree,\n",
    "        samples=n_samples,\n",
    "        impurity=impurity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de l'arbre\n",
    "print(\"Construction de l'arbre de decision...\")\n",
    "tree = build_tree(X_encoded, y_encoded, max_depth=3)\n",
    "print(\"Arbre construit avec succes!\")\n",
    "print(f\"\\nRacine: {tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fonction de prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(x, node):\n",
    "    \"\"\"\n",
    "    Predit la classe pour une seule instance.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    x : Series\n",
    "        Une instance (ligne du DataFrame)\n",
    "    node : Node\n",
    "        Noeud courant de l'arbre\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    int\n",
    "        Classe predite (0 ou 1)\n",
    "    \"\"\"\n",
    "    # Si c'est une feuille, retourner la prediction\n",
    "    if node.is_leaf():\n",
    "        return node.value\n",
    "    \n",
    "    # Sinon, descendre dans le sous-arbre correspondant\n",
    "    if x[node.feature] <= node.threshold:\n",
    "        return predict_one(x, node.left)\n",
    "    else:\n",
    "        return predict_one(x, node.right)\n",
    "\n",
    "\n",
    "def predict(X, tree):\n",
    "    \"\"\"\n",
    "    Predit les classes pour un ensemble d'instances.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Matrice des features\n",
    "    tree : Node\n",
    "        Racine de l'arbre\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    list\n",
    "        Liste des classes predites\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for idx in X.index:\n",
    "        pred = predict_one(X.loc[idx], tree)\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des predictions\n",
    "print(\"Predictions sur l'ensemble d'entrainement:\")\n",
    "y_pred = predict(X_encoded, tree)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "correct = sum(1 for p, t in zip(y_pred, y_encoded) if p == t)\n",
    "accuracy = correct / len(y_encoded)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"\\nPredictions: {y_pred}\")\n",
    "print(f\"Vraies valeurs: {list(y_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisation de l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0, prefix=\"Root\"):\n",
    "    \"\"\"\n",
    "    Affiche l'arbre de decision de maniere textuelle.\n",
    "    \n",
    "    Parametres:\n",
    "    -----------\n",
    "    node : Node\n",
    "        Noeud courant\n",
    "    depth : int\n",
    "        Profondeur actuelle (pour l'indentation)\n",
    "    prefix : str\n",
    "        Prefixe pour l'affichage\n",
    "    \"\"\"\n",
    "    indent = \"    \" * depth\n",
    "    \n",
    "    if node.is_leaf():\n",
    "        class_label = \"oui\" if node.value == 1 else \"non\"\n",
    "        print(f\"{indent}{prefix} -> [Defaut: {class_label}] (n={node.samples})\")\n",
    "    else:\n",
    "        print(f\"{indent}{prefix}: {node.feature} <= {node.threshold}? (n={node.samples}, gini={node.impurity:.3f})\")\n",
    "        print_tree(node.left, depth + 1, \"Oui\")\n",
    "        print_tree(node.right, depth + 1, \"Non\")\n",
    "\n",
    "\n",
    "print(\"Structure de l'arbre de decision:\")\n",
    "print(\"=\" * 60)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_manual(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcule la matrice de confusion.\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    dict\n",
    "        Dictionnaire avec TP, TN, FP, FN\n",
    "    \"\"\"\n",
    "    tp = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 1)\n",
    "    tn = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 0)\n",
    "    fp = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 1)\n",
    "    fn = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 0)\n",
    "    \n",
    "    return {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}\n",
    "\n",
    "\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "cm = confusion_matrix_manual(list(y_encoded), y_pred)\n",
    "\n",
    "print(\"Matrice de confusion:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"                  Prediction\")\n",
    "print(f\"                  Non     Oui\")\n",
    "print(f\"Reel  Non         {cm['TN']:3d}     {cm['FP']:3d}\")\n",
    "print(f\"      Oui         {cm['FN']:3d}     {cm['TP']:3d}\")\n",
    "print()\n",
    "print(f\"Precision: {accuracy:.2%}\")\n",
    "if cm['TP'] + cm['FP'] > 0:\n",
    "    precision = cm['TP'] / (cm['TP'] + cm['FP'])\n",
    "    print(f\"Precision (positive): {precision:.2%}\")\n",
    "if cm['TP'] + cm['FN'] > 0:\n",
    "    recall = cm['TP'] / (cm['TP'] + cm['FN'])\n",
    "    print(f\"Rappel: {recall:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFin du notebook - Arbre de decision from scratch\")\n",
    "print(\"L'arbre est pret a etre compare avec sklearn dans le notebook suivant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}